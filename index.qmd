---
title: "A Unified Probabilistic Framework for Non-Stationary Heart Rate Variability Analysis"
subtitle: "Modeling the Dynamic Evolution of Autonomic Control"
date-modified: today
execute: 
  echo: false
author: 
  - name: "Matías Castillo-Aguilar"
    email: m99castillo@gmail.com
    orcid: 0000-0001-7291-247X
format: 
  html: 
    fig-format: svg
    title-block-banner: true
    title-block-style: manuscript
    toc: true
    toc-location: right
  pdf: 
    fig-format: pdf
    fig-dpi: 500
    documentclass: article
fig-width: 8
fig-height: 6
editor_options: 
  chunk_output_type: console
---

## Introduction

The rhythm of the human heart, far from being a simple, constant beat, is a complex and dynamic signal reflecting the continuous interplay between an organism and its internal and external environments. The precise timing between successive heartbeats, measured as the R-R interval (RRi), is a primary non-invasive proxy for autonomic nervous system (ANS) activity. The analysis of variations in this interval, a discipline known as heart rate variability (HRV), has become a cornerstone for assessing cardiovascular health, stress responses, and overall physiological state. This variability arises from the coordinated actions of multiple regulatory systems, including the sympathetic and parasympathetic branches of the ANS, baroreflexes, and thermoregulatory mechanisms.

Despite its utility, a significant limitation of traditional HRV analysis is its reliance on time-domain or frequency-domain metrics derived from static, short-term data windows. While such methods may offer insights into a snapshot of a physiological state under controlled conditions, they are fundamentally ill-suited to capture the dynamic, non-stationary nature of RRi signals during physiological transitions or stress, such as exercise, cognitive tasks, or pharmacologic interventions. The implicit assumption of stationarity in these fixed-window approaches can obscure subtle, yet physiologically critical, shifts in heart rate and its underlying variability. Furthermore, these conventional analyses often fail to establish a direct mechanistic link between observed changes in HRV and the underlying physiological processes responsible for them. For instance, a generalized decrease in HRV may be interpreted as a withdrawal of parasympathetic tone but could also stem from a complex shift in the balance of different frequency components of autonomic modulation. Disentangling these potential causes necessitates a more sophisticated, unified modeling paradigm.

Attempts to address these limitations have been made using a variety of modeling approaches, but these have often fallen short. For instance, state-space models have shown promise in tracking the evolution of cardiac dynamics, but their complexity can make parameter estimation difficult and their physiological interpretability limited. While time-frequency analysis methods, such as wavelets, can successfully visualize the time-varying nature of spectral content, they typically do not provide a generative model for testing specific physiological hypotheses. Moreover, they often lack a principled way to separate structured physiological variability from unstructured noise. Other efforts have focused on non-linear dynamics and fractal analysis, but these models are often phenomenological, describing the properties of the signal without offering a clear, mechanistic link to the underlying physiology. Consequently, no existing model provides a unified, probabilistic framework that can simultaneously capture and mechanistically interpret changes in both the mean RRi and its multi-component variability.

To advance the field beyond these constraints, a new generation of statistical models is clearly needed. These models must transcend simple descriptive statistics to provide a unified framework that simultaneously captures the time-varying nature of both the mean heart rate and the dynamic evolution of its multi-timescale variability. Such a framework should explicitly address the non-stationarity inherent to physiological signals, obviating the need for arbitrary, fixed-length analysis windows. It must be capable of decomposing the signal into its distinct components, separating the gross, underlying trends in heart rate from the structured, oscillatory variability that represents physiological regulation. Crucially, the model's parameters should have a direct, interpretable link to specific physiological processes, such as autonomic tone, sympathetic-parasympathetic balance, and the dynamics of recovery. As a probabilistic framework, it should also provide a principled means of quantifying the uncertainty associated with all parameter estimates, moving beyond a reliance on point estimates to offer a more complete picture of the physiological state.

This paper presents a novel probabilistic framework for analyzing non-stationary RRi signals. Our approach directly confronts these challenges by formulating the RRi signal as a continuous stochastic process. This model decomposes the signal into a deterministic mean trajectory and a time-varying total standard deviation, both of which are constructed mechanistically. The model's key innovations include a mechanistic model for the mean RRi that uses a flexible double-logistic function to allow for the direct estimation of physiologically salient parameters, such as the magnitude of heart rate change and the timing of response and recovery. A core innovation is the explicit decomposition of the total signal variance into components representing structured, oscillatory variability and unstructured, residual noise, which is critical for understanding the sources of change in HRV. We generalize the traditional SDNN metric into a time-varying trajectory, which is also modeled using a logistic function analogous to that for the mean RRi, thereby capturing the dynamic suppression and recovery of total variability in a parsimonious manner. A crucial mathematical inversion within the framework ensures that the amplitude of the synthesized structured signal exactly matches the target SDNN trajectory at every time point, effectively decoupling the total magnitude of variability from its spectral composition and enabling more granular analysis. Finally, the model captures the dynamic allocation of power across different physiological frequency bands by modeling their proportions as a function of a smooth master controller, which allows for a detailed analysis of shifts in spectral balance during physiological transitions.

The primary objective of this study is to introduce and validate this novel probabilistic model for the analysis of non-stationary RRi signals. We aim to demonstrate that this framework provides a more robust, informative, and physiologically interpretable analysis of heart rate dynamics than traditional methods. We hypothesize that the model will accurately and robustly capture the complex, time-varying dynamics of both the mean RRi and its variability during transient physiological perturbations. We further propose that the model's parameters will yield enhanced mechanistic nuance into autonomic control and cardiovascular regulation, thereby serving as a superior tool for both clinical research and basic physiological investigation. Through this work, we seek to establish a new standard for the analysis of time-varying physiological signals.

```{r}
#| include: false
library(ggplot2)
library(data.table)
library(brms)
library(tidybayes)
library(rstan)

theme_set(
  new = theme_classic(base_size = 14) +
    theme(legend.position = "bottom")
)
```

# Methods

## Model formulation

We present a comprehensive generative model for the R–R interval (RRi) signal, observed at a discrete set of time points $\{t_i\}_{i=1}^N$. The model's architecture is designed to deconstruct the signal into its constituent physiological components, providing a mechanistic account of the processes that shape heart rate dynamics. This is achieved by conceptualizing the signal as a probabilistic process controlled by a time-varying mean, $\mu(t_i)$, and a partitioned, time-varying standard deviation. This sophisticated approach moves beyond simple curve-fitting to formalize a theory of autonomic control and its temporal evolution.

The cornerstone of the model is the partitioning of the total signal variance into two distinct, time-dependent components: a structured variance, $\sigma^2_{\text{struct}}(t_i)$, which captures the physiologically meaningful, oscillatory patterns of heart rate variability (HRV), and a residual variance, $\sigma^2_{\text{resid}}(t_i)$, which accounts for unstructured, moment-to-moment fluctuations or measurement noise. The complete observation model, which integrates these components, is defined by the Normal likelihood in @eq-full-likelihood.

$$
\mathrm{RRi}(t_i) \sim \mathcal{N}\left(\mu(t_i), \sigma_{\text{resid}}(t_i)\right)
$${#eq-full-likelihood}

The core of the model lies in the construction of the mean and variance components from a shared set of underlying dynamic functions. The mean trajectory, $\mu(t_i)$, is a superposition of a smoothly varying baseline trend and the synthesized structured signal itself, as shown in @eq-mean-model.

$$
\mu(t_i)
= \underbrace{\mathrm{RR_{base}}(t_i)}_{\substack{\text{Gross}\\\text{RRi Trend}}}
+
\underbrace{A(t_i) \cdot \sum_{j=1}^{J} p_j(t_i) \cdot S_j(t_i)}_{\substack{\text{Structured Variability Signal}}}
$${#eq-mean-model}

Here, $\mathrm{RR_{base}}(t_i)$ represents the gross, underlying heart period trajectory. The structured variability signal is synthesized from a set of dynamically evolving spectral oscillators, $S_j(t_i)$, which represent activity in different physiological frequency bands ($j=1,2,3$ for VLF, LF, and HF, respectively). These oscillators are weighted by time-varying proportions, $p_j(t_i)$, and their overall magnitude is controlled by a scaling amplitude, $A(t_i)$, which is deterministically calculated to ensure the signal's variance matches the target structured variance, $\sigma^2_{\text{struct}}(t_i)$.

A pivotal feature is a dynamic trajectory for the total signal variability, denoted $\mathrm{SDNN}(t_i)$, which is then partitioned into its structured and residual components. This partition is controlled by a parameter, $w \in [0, 1]$, which represents the fraction of total variance attributable to the structured component, as defined in @eq-var-structure.

$$
\begin{aligned}
\sigma^2_{\text{struct}}(t_i) &= w \cdot \mathrm{SDNN}(t_i)^2 \\
\sigma^2_{\text{resid}}(t_i) &= (1-w) \cdot \mathrm{SDNN}(t_i)^2
\end{aligned}
$${#eq-var-structure}

This formulation allows the model to simultaneously learn not only how the total amount of HRV changes over time (via $\mathrm{SDNN}(t_i)$), but also how the nature of that variability evolves—that is, the balance between predictable, oscillatory patterns and unpredictable noise (via $w$). This unified analysis facilitates a deeper understanding of autonomic regulation by capturing phenomena across both time and frequency domains within a single, coherent inferential framework.

### Baseline heart period and total variability trajectories

The model posits that the primary trends in both the mean heart period and its total variability are driven by a common underlying physiological response to a stimulus. To capture this, both the $\mathrm{RR_{base}}(t_i)$ and $\mathrm{SDNN}(t_i)$ trajectories are parameterized using the same flexible double-logistic functional form.

The baseline heart period, $\mathrm{RR_{base}}(t_i)$, which quantifies the gross, underlying variations in the mean R–R interval, is defined in @eq-rri-baseline-model.

$$
\mathrm{RR_{base}}(t_i) =
\underbrace{\alpha_r}_{\substack{\text{Resting RRi}}}
-
\underbrace{\beta_r \cdot \mathcal{D}_{1}(t_i)}_{\substack{\text{Perturbation-induced}\\\text{RRi Drop}}}
+
\underbrace{c_r \beta_r \cdot \mathcal{D}_{2}(t_i)}_{\substack{\text{Post-perturbation}\\\text{RRi Recovery}}}
$${#eq-rri-baseline-model}

In this formulation, $\alpha_r$ represents the initial, stable heart period. The parameter $\beta_r$ signifies the magnitude of the decline in RRi induced by the perturbation. The fractional recovery amplitude is denoted by $c_r$, where $c_r > 1$ indicates an overshoot.

Concurrently, the total instantaneous variability, $\mathrm{SDNN}(t_i)$, follows a parallel dynamic trajectory, as defined in @eq-sdnn-model.

$$
\mathrm{SDNN}(t_i) =
\underbrace{\alpha_s}_{\substack{\text{Resting SDNN}}}
-
\underbrace{\beta_s \cdot \mathcal{D}_{1}(t_i)}_{\substack{\text{Perturbation-induced}\\\text{SDNN Drop}}}
+
\underbrace{c_s \beta_s \cdot \mathcal{D}_{2}(t_i)}_{\substack{\text{Post-perturbation}\\\text{SDNN Recovery}}}
$${#eq-sdnn-model}

Here, $\alpha_s$, $\beta_s$, and $c_s$ are analogous to their counterparts in the baseline model, representing the resting total SDNN, the magnitude of its suppression, and its fractional recovery, respectively. The dynamics for both trajectories are driven by a shared pair of logistic transition functions, $\mathcal{D}_{1}(t_i)$ and $\mathcal{D}_{2}(t_i)$, defined in @eq-logistic-components.

$$
\begin{aligned}
\mathcal{D}_{1}(t_i) &= \left(1+ e^{-\lambda (t_i - \tau)}\right)^{-1} \\
\mathcal{D}_{2}(t_i) &= \left(1+ e^{-\phi (t_i - \tau - \delta)}\right)^{-1}
\end{aligned}
$${#eq-logistic-components}

The shared timing parameters enforce a strong physiological coupling: $\tau$ is the inflection point of the initial response, with rate $\lambda$. The second transition, representing recovery, is offset by a delay $\delta$ and proceeds at a rate $\phi$. This shared structure ensures that changes in the magnitude of variability are temporally synchronized with changes in the mean heart period, while still allowing their relative magnitudes and recovery profiles to differ.

### Generative model for the structured signal

The structured component of the signal is where the model's spectral properties are defined. Its construction involves three key elements: the dynamic spectral proportions, the latent spectral oscillators, and the deterministic amplitude inversion that ties them to the target variance.

#### Dynamic frequency band proportions

The proportions $p_j(t_i)$ dictate how the total structured variance, $\sigma^2_{\text{struct}}(t_i)$, is allocated across the different frequency bands at each moment. The model captures the evolution of these proportions as a smooth transition between two distinct spectral states: a baseline state ($\vec\pi_{\text{base}}$) and a perturbed state ($\vec\pi_{\text{pert}}$). The transition is orchestrated by a single master controller function, $C(t_i)$, as shown in the convex combination of @eq-pj-using-ct.

$$
\vec{p}(t_i) = (1 - C(t_i)) \cdot \vec\pi_{\text{base}} + C(t_i) \cdot \vec\pi_{\text{pert}}
$${#eq-pj-using-ct}

Here, $\vec\pi_{\text{base}}$ and $\vec\pi_{\text{pert}}$ are simplex vectors representing the characteristic spectral distributions at rest and during peak perturbation. The master controller, $C(t_i)$, is itself built from the same logistic building blocks, ensuring the spectral transition is synchronized with the primary physiological response, as defined in @eq-master-controller.

$$
C(t_i) = \mathcal{D}_{1}(t_i) \cdot \left(1 - c_c \cdot \mathcal{D}_{2}(t_i)\right)
$${#eq-master-controller}

This function naturally transitions from 0 towards 1, with the parameter $c_c \in [0, 1]$ allowing for an incomplete spectral recovery.

#### Latent multi-sine spectral oscillators

The model explicitly learns the phase and amplitude of the underlying spectral components from the data. Each oscillator, $S_j(t_i)$, is constructed as a superposition of $K_j$ sinusoids with pre-specified frequencies but with unknown amplitudes. The signal for band $j$ is given by @eq-multi-sine-fun.

$$
S_j(t_i) = \sum_{k=1}^{K_j} \left[ u_{j,k}^{(\sin)} \sin(2 \pi f_{j,k} t_i) + u_{j,k}^{(\cos)} \cos(2 \pi f_{j,k} t_i) \right]
$${#eq-multi-sine-fun}

The coefficients $u_{j,k}^{(\sin)}$ and $u_{j,k}^{(\cos)}$ are the unknown amplitudes for the sine and cosine components at each frequency $f_{j,k}$. To ensure a realistic spectral structure and aid inference, we place a hierarchical prior on these coefficients. This is achieved using a non-centered parameterization, where the coefficients are modeled as draws from a Normal distribution whose standard deviation is frequency-dependent, as defined in @eq-hierarchical-prior-spectral.

$$
u_{j,k}^{(\cdot)} \sim \mathcal{N}(0, \sigma_{u} \cdot a_{j,k})
$${#eq-hierarchical-prior-spectral}

Here, the scale of the prior is determined by two components. First, $a_{j,k}$ imposes a power-law relationship with frequency, $a_{j,k} = f_{j,k}^{-b/2}$, where $b$ is a global spectral exponent. This enforces a $1/f^b$ noise structure, a common characteristic of biological signals. Second, $\sigma_{u}$ is a single global scaling parameter that adjusts the overall power across all bands. Finally, after construction, each oscillator signal $S_j(t_i)$ is mean-centered to ensure it represents pure variability.

#### Deterministic amplitude inversion

The final step is to ensure that the synthesized structured signal, $X(t_i) = A(t_i) \sum_{j=1}^J p_j(t_i) S_j(t_i)$, has a variance equal to the target structured variance, $\sigma^2_{\text{struct}}(t_i)$, at every time point. A key feature of this model is that it does not assume the sinusoids form an orthogonal basis over the discrete, finite time domain. Instead, it computes the exact sample variance for each synthesized oscillator, $\mathrm{Var}[S_j(t_i)]$, given the current values of its coefficients.

Let $\mathbf{\Sigma}_S$ be the diagonal $3 \times 3$ matrix whose entries are these computed variances, $\mathbf{\Sigma}_S[j, j] = \mathrm{Var}[S_j(t_i)]$. Assuming independence between the bands, the variance of the weighted sum is given by the quadratic form in @eq-weighted-sum.

$$
\mathrm{Var}\left[\sum_{j=1}^J p_j(t_i) S_j(t_i)\right] = \vec{p}(t_i)^\top \mathbf{\Sigma}_S \; \vec{p}(t_i)
$${#eq-weighted-sum}

The variance of the complete structured signal is $\mathrm{Var}[X(t_i)] = A(t_i)^2 \cdot \left(\vec{p}(t_i)^\top \mathbf{\Sigma}_S \; \vec{p}(t_i)\right)$. To match our target, we set this equal to $\sigma^2_{\text{struct}}(t_i) = w \cdot \mathrm{SDNN}(t_i)^2$. Solving for $A(t_i)$ yields the critical inversion formula in @eq-amplitude-inversion.

$$
A(t_i) = \frac{\sqrt{w} \cdot \mathrm{SDNN}(t_i)}{\sqrt{\vec{p}(t_i)^\top \mathbf{\Sigma}_S \; \vec{p}(t_i)}}
$${#eq-amplitude-inversion}

This inversion is essential. It dynamically adjusts the amplitude of the synthesized spectral signal to ensure its contribution to the total variance is exactly as prescribed by the model's high-level parameters ($\mathrm{SDNN}(t_i)$ and $w$), thereby connecting the time-domain and frequency-domain components of the model.

### Model Parameterization and Priors

To ensure numerical stability and efficient sampling, all model parameters are estimated on an unconstrained real-valued scale ($\mathbb{R}$). Priors are placed on these unconstrained parameters, which are then transformed back to their constrained, physically meaningful scales within the model.

#### Timing, Rate, and Magnitude Parameters

Parameters constrained to a specific interval are parameterized on the logit scale, while positive parameters are on the log scale. For instance, the timing parameters $\tau$ and $\delta$ are mapped to the observed time interval ($t_\text{range}$) and the remaining time, respectively, using the inverse logit transformation, such that $\tau = \text{logit}^{-1}(\tau_\text{logit}) \cdot t_\text{range} + t_\text{min}$ and $\delta = \text{logit}^{-1}(\delta_\text{logit}) \cdot (t_\text{range} - \tau)$.

The positive rate parameters $\lambda$ and $\phi$ are simply log-transformed, i.e., $\lambda = \exp(\lambda_\text{log})$. The recovery coefficients for the time-domain components ($c_r,c_s$) are mapped to the interval $[0, 2]$, while the recovery parameter for spectral components ($c_c$) is mapped to the $[0, 1]$ interval, using a scaled logit function, $c = \text{logit}^{-1}(c_\text{logit}) \cdot \text{scale}$. Similarly, the fraction of structured variance, $w$, is constrained between 0 and 1 via $w = \text{logit}^{-1}(w_{\text{logit}})$.

The magnitude parameters ($\alpha_r, \beta_r, \alpha_s, \beta_s$) are scaled relative to data-derived quantities to create dimensionless parameters whose priors are easier to specify. For instance, $\alpha_r$ is defined as $\alpha_r = \text{logit}^{-1}(\alpha_{r, \text{logit}}) \cdot 2 \cdot \text{rr}_\text{range} + \text{rr}_\text{min}$, which then scales its corresponding $\beta$ parameter, $\beta_r = \text{logit}^{-1}(\beta_{r, \text{logit}}) \cdot \alpha_r$. A similar relationship holds for $\alpha_s$ and $\beta_s$, which are scaled by the data's standard deviation. These transformations ensure the sampler explores a valid and well-behaved parameter space.

#### Spectral and Oscillator Parameters

The spectral proportions, $\vec\pi_{\text{base}}$ and $\vec\pi_{\text{pert}}$, are mapped from the 3-dimensional simplex to 2-dimensional real vectors, $\vec{y} = [y_1, y_2]$, using the additive log-ratio (ALR) transformation. The model estimates the unconstrained vectors ($\vec{y}_{\text{base, log}}, \vec{y}_{\text{pert, log}}$), which are mapped back to the simplex via the softmax function.

To improve sampling efficiency, the oscillator amplitudes, $u_{j,k}$, are handled with a non-centered parameterization. Instead of estimating the highly correlated $u$ values directly, the model estimates standard normal deviates, $z_{j,k}$. These are then scaled by the hierarchical prior to construct the final amplitudes as $u_{j,k} = z_{j,k} \cdot \sigma_{u} \cdot a_{j,k}$, where $a_{j,k} = f_{j,k}^{-b/2}$ is a frequency-dependent component and $\sigma_u$ is a global scale parameter. This technique dramatically reduces posterior correlations between parameters. Weakly informative priors are placed on all unconstrained parameters, allowing the data to drive the final inference.

## Simulation Studies

To evaluate the model's performance, we conducted a series of simulation studies. The objectives were to assess the model's ability to recover known ground-truth parameters from synthetic data and to quantitatively benchmark its reconstruction of key HRV dynamics against conventional, windowed analysis techniques. Synthetic RRi time series were generated using the model's own generative structure with pre-specified parameter values. This process provided datasets with perfectly known underlying dynamics for $\mathrm{RR}(t_i)$, $\mathrm{SDNN}(t_i)$, and $p_j(t_i)$, serving as an objective gold standard for evaluation.

We designed three distinct scenarios to probe the model's capabilities under diverse and challenging conditions. These scenarios: (1) a classic sympatho-vagal response, (2) an incomplete recovery with spectral persistence, and (3) a high noise with a stable spectrum, were chosen specifically to test the limitations inherent in standard analysis methods. Each simulated dataset was analyzed with our full Bayesian model and, for comparison, with conventional techniques: a sliding-window analysis for time-domain metrics and a Short-Time Fourier Transform (STFT) for spectral dynamics.

### Time-domain trajectory reconstruction

The capacity to accurately capture time-domain dynamics was evaluated by comparing the model's continuous estimates of $\mathrm{RR}(t_i)$ and $\mathrm{SDNN}(t_i)$ against the stepwise approximations derived from a standard sliding-window mean and standard deviation. The fidelity of each method's reconstruction was quantified against the ground-truth trajectories using two complementary metrics. The root mean squared error (RMSE) was used to measure the average magnitude of the estimation error, while the coefficient of determination ($R^2$) was used to assess the proportion of variance in the true signal captured by the estimate.

### Spectral dynamics reconstruction

To evaluate the reconstruction of spectral dynamics, our model's continuous estimates of the spectral proportions, $p_j(t_i)$, were compared against those derived from an STFT. For a direct comparison, the spectrogram generated by the STFT was normalized at each time step to yield proportional power within the VLF, LF, and HF bands. The performance of both methods was then assessed by comparing their estimated trajectories to the known ground-truth proportions using both RMSE and $R^2$. This comparative framework was designed to objectively quantify the trade-offs in temporal and frequency resolution inherent to windowed methods versus the continuous estimation provided by our model, especially in the presence of rapid transitions or low signal-to-noise ratios. As part of the model's internal validation, we also confirmed that the 95% posterior credible intervals for all generative parameters consistently contained the known ground-truth values, ensuring both inferential accuracy and appropriate uncertainty quantification.

# Results

[...].

# Discussion

[...].
